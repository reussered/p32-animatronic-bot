// generic_spi_display component implementation
// Generic SPI display interface with double-buffered DMA chunking

#include "esp_log.h"
#include "esp_heap_caps.h"
#include "driver/spi_master.h"
#include "freertos/FreeRTOS.h"
#include "freertos/task.h"
#include "freertos/semphr.h"
#include "components/spi_display_bus.hdr"
#include "driver/gpio.h"

static const char *TAG_generic_spi_display = "generic_spi_display";

// Dynamic chunking configuration
#define MIN_CHUNK_HEIGHT 2         // Minimum chunk size (too small = excessive overhead)
#define MAX_CHUNK_HEIGHT 40        // Maximum chunk size (too large = poor fairness)
#define INITIAL_CHUNK_HEIGHT 10    // Starting point for adaptive algorithm
#define MAX_DISPLAY_WIDTH 480      // ILI9341 width (mouth), eyes are 240x240
#define MAX_DISPLAY_HEIGHT 320     // ILI9341 height
#define BYTES_PER_PIXEL 3          // RGB666

// Dynamic chunk sizing state
typedef struct {
    uint16_t current_chunk_height;     // Current adaptive chunk height
    uint32_t act_call_count;           // Total calls to generic_spi_display_act()
    uint32_t dma_busy_count;           // Calls where DMA was busy (couldn't start new transfer)
    uint32_t dma_started_count;        // Calls where new DMA transfer was started
    uint32_t adjustment_timer;         // Counter for periodic adjustments
    size_t current_buffer_size;        // Current allocated buffer size in bytes
} dynamic_chunk_state_t;

static dynamic_chunk_state_t chunk_state = {
    .current_chunk_height = INITIAL_CHUNK_HEIGHT,
    .act_call_count = 0,
    .dma_busy_count = 0,
    .dma_started_count = 0,
    .adjustment_timer = 0,
    .current_buffer_size = 0
};

#define CHUNK_SIZE_BYTES (MAX_DISPLAY_WIDTH * chunk_state.current_chunk_height * BYTES_PER_PIXEL)

// Multi-display round-robin scheduling
typedef enum {
    DISPLAY_LEFT_EYE = 0,   // CS=3
    DISPLAY_RIGHT_EYE = 1,  // CS=6  
    DISPLAY_MOUTH = 2,      // CS=? (to be determined)
    DISPLAY_COUNT = 3
} display_id_t;

// Per-display state tracking
typedef struct {
    uint8_t cs_pin;              // Chip select pin for this display
    uint16_t* framebuffer;       // Source PSRAM framebuffer for this display
    uint16_t width;              // Display width in pixels
    uint16_t height;             // Display height in pixels
    size_t current_chunk;        // Which chunk we're processing (0-63 for mouth, 0-47 for eyes)
    size_t total_chunks;         // Total chunks for this display
    bool frame_pending;          // This display has a new frame to send
    bool chunks_remaining;       // This display still has chunks to send
} display_state_t;

// Global DMA state tracking
typedef struct {
    uint8_t* buffer_a;           // Double buffer A (shared across displays)
    uint8_t* buffer_b;           // Double buffer B (shared across displays)
    uint8_t* active_buffer;      // Currently transmitting
    uint8_t* loading_buffer;     // Currently loading from PSRAM
    bool psram_dma_active;       // PSRAM->buffer DMA in progress
    bool spi_dma_active;         // Buffer->display DMA in progress
    SemaphoreHandle_t dma_complete_sem;  // DMA completion notification
    
    // Round-robin scheduling
    display_id_t current_display;    // Which display is currently being served
    display_state_t displays[DISPLAY_COUNT];  // Per-display state
} dma_chunking_state_t;

static dma_chunking_state_t dma_state = {0};

// Simple adaptive chunk size adjustment - just respond to DMA completion ratio
#define ADJUSTMENT_INTERVAL 200  // Adjust every 200 calls to act()
#define TARGET_BUSY_RATIO 50     // Target: ~50% of calls should find DMA busy

static void adjust_chunk_size(void) {
    chunk_state.adjustment_timer++;
    if (chunk_state.adjustment_timer < ADJUSTMENT_INTERVAL) return;
    
    // Simple algorithm: just respond to DMA completion ratio
    uint32_t busy_ratio_percent = 0;
    if (chunk_state.act_call_count > 0) {
        busy_ratio_percent = (chunk_state.dma_busy_count * 100) / chunk_state.act_call_count;
    }
    
    uint16_t old_height = chunk_state.current_chunk_height;
    
    if (busy_ratio_percent < (TARGET_BUSY_RATIO - 10)) {
        // DMA being started too often - increase chunk size by 1 for fewer, larger transfers
        if (chunk_state.current_chunk_height < MAX_CHUNK_HEIGHT) {
            chunk_state.current_chunk_height++;
        }
    } else if (busy_ratio_percent > (TARGET_BUSY_RATIO + 10)) {
        // DMA not started enough - decrease chunk size by 1 for more frequent transfers
        if (chunk_state.current_chunk_height > MIN_CHUNK_HEIGHT) {
            chunk_state.current_chunk_height--;
        }
    }
    
    // Reallocate buffers if chunk size changed
    
    if (old_height != chunk_state.current_chunk_height) {
        ESP_LOGI(TAG_generic_spi_display, "Adaptive chunk adjustment: %d->%d rows (busy ratio: %lu%%)", 
                 old_height, chunk_state.current_chunk_height, busy_ratio_percent);
        
        // Recalculate buffer sizes and total chunks for all displays
        size_t new_buffer_size = MAX_DISPLAY_WIDTH * chunk_state.current_chunk_height * BYTES_PER_PIXEL;
        if (new_buffer_size != chunk_state.current_buffer_size) {
            // Reallocate buffers if size changed significantly
            if (dma_state.buffer_a) heap_caps_free(dma_state.buffer_a);
            if (dma_state.buffer_b) heap_caps_free(dma_state.buffer_b);
            
            dma_state.buffer_a = (uint8_t*)heap_caps_malloc(new_buffer_size, MALLOC_CAP_DMA | MALLOC_CAP_8BIT);
            dma_state.buffer_b = (uint8_t*)heap_caps_malloc(new_buffer_size, MALLOC_CAP_DMA | MALLOC_CAP_8BIT);
            
            if (dma_state.buffer_a && dma_state.buffer_b) {
                chunk_state.current_buffer_size = new_buffer_size;
                dma_state.active_buffer = dma_state.buffer_a;
                dma_state.loading_buffer = dma_state.buffer_b;
                
                // Recalculate total chunks for all displays
                for (int i = 0; i < DISPLAY_COUNT; i++) {
                    dma_state.displays[i].total_chunks = 
                        (dma_state.displays[i].height + chunk_state.current_chunk_height - 1) / chunk_state.current_chunk_height;
                }
                
                ESP_LOGI(TAG_generic_spi_display, "Reallocated buffers: %zu bytes each", new_buffer_size);
            } else {
                ESP_LOGE(TAG_generic_spi_display, "Failed to reallocate adaptive buffers!");
                chunk_state.current_chunk_height = old_height; // Revert change
            }
        }
    }
    
    // Reset statistics for next measurement period
    chunk_state.adjustment_timer = 0;
    chunk_state.act_call_count = 0;
    chunk_state.dma_busy_count = 0;
    chunk_state.dma_started_count = 0;
}

// Display commands
#define GC9A01_SWRESET 0x01
#define GC9A01_SLPOUT 0x11
#define GC9A01_DISPON 0x29
#define GC9A01_CASET  0x2A
#define GC9A01_RASET  0x2B
#define GC9A01_RAMWR  0x2C

// DMA completion callback - triggers continued round-robin processing
static void IRAM_ATTR spi_dma_callback(spi_transaction_t *trans) {
    BaseType_t xHigherPriorityTaskWoken = pdFALSE;
    dma_state.spi_dma_active = false;
    
    // Trigger continued processing by calling the act function
    // This ensures the pipeline continues with the next chunk or next display
    // Note: This is a simplified approach - in production you might want to use a task notification
    xSemaphoreGiveFromISR(dma_state.dma_complete_sem, &xHigherPriorityTaskWoken);
    
    if (xHigherPriorityTaskWoken) {
        portYIELD_FROM_ISR();
    }
}

// Internal helper functions to send commands and data
static void generic_spi_write_data_blocking(spi_device_handle_t spi, const uint8_t *data, size_t len) {
    if (!spi) return;
    esp_err_t ret;
    spi_transaction_t t;
    if (len == 0) return;
    memset(&t, 0, sizeof(t));
    t.length = len * 8;
    t.tx_buffer = data;
    t.user = (void*)1; // D/C = 1 for data
    ret = spi_device_polling_transmit(spi, &t);
    ESP_ERROR_CHECK(ret);
}

// Non-blocking DMA transfer for chunk data
static esp_err_t generic_spi_write_data_dma(spi_device_handle_t spi, const uint8_t *data, size_t len) {
    if (!spi || len == 0) return ESP_ERR_INVALID_ARG;
    
    static spi_transaction_t trans = {0};
    trans.length = len * 8;
    trans.tx_buffer = data;
    trans.user = (void*)1; // D/C = 1 for data
    
    dma_state.spi_dma_active = true;
    esp_err_t ret = spi_device_queue_trans(spi, &trans, portMAX_DELAY);
    return ret;
}

static void spi_write_command(spi_device_handle_t spi, const uint8_t cmd) {
    if (!spi) return;
    esp_err_t ret;
    spi_transaction_t t;
    memset(&t, 0, sizeof(t));
    t.length = 8;
    t.tx_buffer = &cmd;
    t.user = (void*)0; // D/C = 0 for command
    ret = spi_device_polling_transmit(spi, &t);
    ESP_ERROR_CHECK(ret);
}

esp_err_t generic_spi_display_init(void) {
    ESP_LOGI(TAG_generic_spi_display, "Initializing generic SPI display with double-buffered DMA chunking, CS=%d", cur_spi_display_pin.cs);
    
    // Initialize DMA state (one-time global setup)
    static bool dma_initialized = false;
    if (!dma_initialized) {
        memset(&dma_state, 0, sizeof(dma_state));
        
        // Create semaphore for DMA completion signaling
        dma_state.dma_complete_sem = xSemaphoreCreateBinary();
        if (!dma_state.dma_complete_sem) {
            ESP_LOGE(TAG_generic_spi_display, "Failed to create DMA completion semaphore");
            return ESP_ERR_NO_MEM;
        }
        
        // Initialize adaptive chunk sizing
        chunk_state.current_buffer_size = MAX_DISPLAY_WIDTH * chunk_state.current_chunk_height * BYTES_PER_PIXEL;
        
        // Allocate initial shared double buffers in DMA-capable memory
        dma_state.buffer_a = (uint8_t*)heap_caps_malloc(chunk_state.current_buffer_size, MALLOC_CAP_DMA | MALLOC_CAP_8BIT);
        dma_state.buffer_b = (uint8_t*)heap_caps_malloc(chunk_state.current_buffer_size, MALLOC_CAP_DMA | MALLOC_CAP_8BIT);
        
        if (!dma_state.buffer_a || !dma_state.buffer_b) {
            ESP_LOGE(TAG_generic_spi_display, "Failed to allocate initial DMA buffers (%zu bytes each)", chunk_state.current_buffer_size);
            return ESP_ERR_NO_MEM;
        }
        
        // Initialize buffer pointers
        dma_state.active_buffer = dma_state.buffer_a;
        dma_state.loading_buffer = dma_state.buffer_b;
        dma_state.current_display = DISPLAY_LEFT_EYE;  // Start with left eye
        
        // Initialize per-display state
        dma_state.displays[DISPLAY_LEFT_EYE].cs_pin = 3;
        dma_state.displays[DISPLAY_LEFT_EYE].width = 240;
        dma_state.displays[DISPLAY_LEFT_EYE].height = 240;
        
        dma_state.displays[DISPLAY_RIGHT_EYE].cs_pin = 6;  
        dma_state.displays[DISPLAY_RIGHT_EYE].width = 240;
        dma_state.displays[DISPLAY_RIGHT_EYE].height = 240;
        
        dma_state.displays[DISPLAY_MOUTH].cs_pin = 10;  // TODO: Determine actual CS pin for mouth
        dma_state.displays[DISPLAY_MOUTH].width = 480;
        dma_state.displays[DISPLAY_MOUTH].height = 320;
        
        for (int i = 0; i < DISPLAY_COUNT; i++) {
            dma_state.displays[i].total_chunks = (dma_state.displays[i].height + chunk_state.current_chunk_height - 1) / chunk_state.current_chunk_height;
            dma_state.displays[i].current_chunk = 0;
            dma_state.displays[i].frame_pending = false;
            dma_state.displays[i].chunks_remaining = false;
        }
        
        dma_initialized = true;
        ESP_LOGI(TAG_generic_spi_display, "Adaptive DMA system initialized: %zu bytes per buffer, %d displays, initial chunk height: %d", 
                 chunk_state.current_buffer_size, DISPLAY_COUNT, chunk_state.current_chunk_height);
    }

    if (cur_spi_display_pin.handle == NULL) {
        ESP_LOGE(TAG_generic_spi_display, "SPI handle is NULL, cannot initialize display.");
        return ESP_FAIL;
    }

    // Hardware reset
    if (cur_spi_display_pin.rst != -1) {
        gpio_set_level((gpio_num_t)cur_spi_display_pin.rst, 0);
        vTaskDelay(pdMS_TO_TICKS(100));
        gpio_set_level((gpio_num_t)cur_spi_display_pin.rst, 1);
        vTaskDelay(pdMS_TO_TICKS(100));
    }

    // Software reset
    spi_write_command(cur_spi_display_pin.handle, GC9A01_SWRESET);
    vTaskDelay(pdMS_TO_TICKS(150));

    // Sleep out
    spi_write_command(cur_spi_display_pin.handle, GC9A01_SLPOUT);
    vTaskDelay(pdMS_TO_TICKS(500));

    // Display on
    spi_write_command(cur_spi_display_pin.handle, GC9A01_DISPON);
    vTaskDelay(pdMS_TO_TICKS(100));

    ESP_LOGI(TAG_generic_spi_display, "Display with CS=%d initialized successfully", cur_spi_display_pin.cs);
    return ESP_OK;
}

// Get framebuffer for a specific display
static uint16_t* get_framebuffer_for_display(display_id_t display_id) {
    switch (display_id) {
        case DISPLAY_LEFT_EYE:
            return goblin_left_eye_get_buffer();
        case DISPLAY_RIGHT_EYE:
            return goblin_right_eye_get_buffer();
        case DISPLAY_MOUTH:
            // TODO: Implement goblin_mouth_get_buffer() or similar
            return nullptr; // Placeholder for now
        default:
            return nullptr;
    }
}

// Find next display with pending work (round-robin)
static display_id_t find_next_display_with_work(void) {
    for (int i = 0; i < DISPLAY_COUNT; i++) {
        display_id_t check_display = (display_id_t)((dma_state.current_display + i) % DISPLAY_COUNT);
        if (dma_state.displays[check_display].frame_pending || 
            dma_state.displays[check_display].chunks_remaining) {
            return check_display;
        }
    }
    return DISPLAY_COUNT; // No work found
}

// Switch SPI bus to target a specific display
static void switch_to_display(display_id_t display_id) {
    if (display_id >= DISPLAY_COUNT) return;
    
    // Update current display selection
    dma_state.current_display = display_id;
    
    // Switch SPI CS pin (this might need to be implemented differently based on your SPI bus setup)
    // For now, assume we update the global cur_spi_display_pin
    cur_spi_display_pin.cs = dma_state.displays[display_id].cs_pin;
    
    ESP_LOGD(TAG_generic_spi_display, "Switched to display %d (CS=%d)", 
             display_id, dma_state.displays[display_id].cs_pin);
}

// Convert and load a chunk from PSRAM framebuffer to DMA buffer
static void load_chunk_from_psram(display_id_t display_id, size_t chunk_index, uint8_t* dest_buffer) {
    uint16_t* source_framebuffer = dma_state.displays[display_id].framebuffer;
    if (!source_framebuffer || !dest_buffer) return;
    
    uint16_t display_width = dma_state.displays[display_id].width;
    uint16_t display_height = dma_state.displays[display_id].height;
    
    size_t start_row = chunk_index * chunk_state.current_chunk_height;
    size_t end_row = (chunk_index + 1) * chunk_state.current_chunk_height;
    if (end_row > display_height) end_row = display_height;
    
    size_t rows_in_chunk = end_row - start_row;
    
    // Convert RGB565 (PSRAM) to RGB666 (DMA buffer) for this chunk
    for (size_t row = 0; row < rows_in_chunk; row++) {
        for (size_t col = 0; col < display_width; col++) {
            size_t src_index = (start_row + row) * display_width + col;
            size_t dest_index = (row * display_width + col) * BYTES_PER_PIXEL;
            
            uint16_t rgb565 = source_framebuffer[src_index];
            
            // Convert RGB565 to RGB666
            uint8_t r = ((rgb565 >> 11) & 0x1F) << 1; // 5->6 bits
            uint8_t g = ((rgb565 >> 5) & 0x3F);       // 6 bits
            uint8_t b = (rgb565 & 0x1F) << 1;        // 5->6 bits
            
            dest_buffer[dest_index] = r << 2;     // 6-bit R to 8-bit
            dest_buffer[dest_index + 1] = g << 2; // 6-bit G to 8-bit  
            dest_buffer[dest_index + 2] = b << 2; // 6-bit B to 8-bit
        }
    }
}

// Set display window for current chunk
static void set_display_window(display_id_t display_id, size_t chunk_index) {
    size_t start_row = chunk_index * chunk_state.current_chunk_height;
    size_t end_row = (chunk_index + 1) * chunk_state.current_chunk_height - 1;
    uint16_t display_height = dma_state.displays[display_id].height;
    uint16_t display_width = dma_state.displays[display_id].width;
    if (end_row >= display_height) end_row = display_height - 1;
    
    // Set column address (0 to display_width-1)
    spi_write_command(cur_spi_display_pin.handle, GC9A01_CASET);
    uint8_t col_data[] = {0x00, 0x00, (display_width - 1) >> 8, (display_width - 1) & 0xFF};
    generic_spi_write_data_blocking(cur_spi_display_pin.handle, col_data, 4);

    // Set row address for this chunk
    spi_write_command(cur_spi_display_pin.handle, GC9A01_RASET);
    uint8_t row_data[] = {start_row >> 8, start_row & 0xFF, end_row >> 8, end_row & 0xFF};
    generic_spi_write_data_blocking(cur_spi_display_pin.handle, row_data, 4);

    // Memory write command
    spi_write_command(cur_spi_display_pin.handle, GC9A01_RAMWR);
}

void generic_spi_display_act(void) {
    // Adaptive chunk sizing - track every call to act()
    chunk_state.act_call_count++;
    
    if (cur_spi_display_pin.handle == NULL) {
        ESP_LOGE(TAG_generic_spi_display, "act: SPI handle is NULL for CS=%d", cur_spi_display_pin.cs);
        return;
    }

    // Identify which display called us and update its framebuffer
    display_id_t calling_display = DISPLAY_COUNT;
    if (cur_spi_display_pin.cs == 3) {
        calling_display = DISPLAY_LEFT_EYE;
    } else if (cur_spi_display_pin.cs == 6) {
        calling_display = DISPLAY_RIGHT_EYE;
    } else if (cur_spi_display_pin.cs == 10) { // TODO: Update with actual mouth CS pin
        calling_display = DISPLAY_MOUTH;
    }

    if (calling_display < DISPLAY_COUNT) {
        // Update framebuffer for the calling display
        uint16_t* framebuffer = get_framebuffer_for_display(calling_display);
        if (framebuffer) {
            dma_state.displays[calling_display].framebuffer = framebuffer;
            dma_state.displays[calling_display].frame_pending = true;
            dma_state.displays[calling_display].current_chunk = 0;
            dma_state.displays[calling_display].chunks_remaining = true;
        }
    }

    // Check if DMA operations are active for adaptive algorithm
    if (!dma_state.psram_dma_active && !dma_state.spi_dma_active) {
        // DMA is idle - we can start new transfer
        chunk_state.dma_started_count++;
        
        // Find next display that needs service (round-robin)
        display_id_t next_display = find_next_display_with_work();
        if (next_display >= DISPLAY_COUNT) {
            return; // No displays need service
        }
        
        // Switch to the selected display
        switch_to_display(next_display);
        
        display_state_t* display = &dma_state.displays[next_display];
        
        // Start new frame or continue existing frame
        if (display->frame_pending) {
            display->frame_pending = false;
            display->current_chunk = 0;
            display->chunks_remaining = true;
        }
        
        if (display->chunks_remaining && display->current_chunk < display->total_chunks) {
            
            // Load chunk into loading buffer
            load_chunk_from_psram(next_display, display->current_chunk, dma_state.loading_buffer);
            
            // Swap buffers for transmission
            uint8_t* temp = dma_state.active_buffer;
            dma_state.active_buffer = dma_state.loading_buffer;
            dma_state.loading_buffer = temp;
            
            // Set display window and start DMA transmission
            set_display_window(next_display, display->current_chunk);
            
            // Calculate actual chunk size (handle leftover rows in final chunk)
            size_t rows_in_chunk = chunk_state.current_chunk_height;
            size_t start_row = display->current_chunk * chunk_state.current_chunk_height;
            if (start_row + rows_in_chunk > display->height) {
                rows_in_chunk = display->height - start_row; // Handle leftover rows
            }
            
            size_t chunk_bytes = display->width * rows_in_chunk * BYTES_PER_PIXEL;
            generic_spi_write_data_dma(cur_spi_display_pin.handle, dma_state.active_buffer, chunk_bytes);
            
            display->current_chunk++;
            
            // Check if this display is done
            if (display->current_chunk >= display->total_chunks) {
                display->chunks_remaining = false;
                ESP_LOGD(TAG_generic_spi_display, "Display %d frame complete", next_display);
            }
        }
    } else {
        // DMA is busy - track this for adaptive algorithm
        chunk_state.dma_busy_count++;
    }
    
    // Run adaptive chunk size adjustment periodically
    adjust_chunk_size();
    
    // Note: When SPI DMA completes, the callback will trigger this function again
    // ensuring continuous round-robin service of all displays
}



